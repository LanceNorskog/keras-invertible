{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Palindromic Deep Learning for MNIST Digits 1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Start with a simple multi-stage autoencoder\n",
        "\n",
        "https://blog.keras.io/building-autoencoders-in-keras.html"
      ],
      "metadata": {
        "id": "cKDtwP6aK3AX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O6-EZfoSkDis"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.python.ops import nn\n",
        "import keras\n",
        "from keras import layers\n",
        "from keras.datasets import mnist\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "(x_train, _), (x_test, _) = mnist.load_data()\n",
        "x_train = x_train.astype('float32') / 255.\n",
        "x_test = x_test.astype('float32') / 255.\n",
        "x_train = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))\n",
        "x_test = x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))\n",
        "print(x_train.shape)\n",
        "print(x_test.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WCuLZ05oklTv",
        "outputId": "09af7c55-7c8b-41d7-fd6d-804da08eefc1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(60000, 784)\n",
            "(10000, 784)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_model(activation_forward, activation_reverse):\n",
        "    input_img = keras.Input(shape=(784,))\n",
        "    encoded = layers.Dense(128, activation=activation_forward)(input_img)\n",
        "    encoded = layers.Dense(64, activation=activation_forward)(encoded)\n",
        "    encoded = layers.Dense(32, activation=activation_forward)(encoded)\n",
        "\n",
        "    decoded = layers.Dense(64, activation=activation_reverse)(encoded)\n",
        "    decoded = layers.Dense(128, activation=activation_reverse)(decoded)\n",
        "    decoded = layers.Dense(784, activation='sigmoid')(decoded)\n",
        "\n",
        "    autoencoder = keras.Model(input_img, decoded)\n",
        "    autoencoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
        "    autoencoder.summary()\n",
        "    return autoencoder\n"
      ],
      "metadata": {
        "id": "_7EusGw9l35D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "activation_forward = 'relu'\n",
        "num_epochs = 1\n",
        "autoencoder = create_model(activation_forward, 'relu')\n",
        "\n",
        "autoencoder.fit(x_train, x_train,\n",
        "                epochs=num_epochs,\n",
        "                batch_size=256,\n",
        "                shuffle=True,\n",
        "                validation_data=(x_test, x_test))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qENqIHumknn3",
        "outputId": "b366f3bf-0686-43cd-8d85-6e9c590906b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "235/235 [==============================] - 9s 32ms/step - loss: 0.2436 - val_loss: 0.1655\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fd65b1b37d0>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "activation_forward = 'sigmoid'\n",
        "num_epochs = 1\n",
        "autoencoder = create_model(activation_forward, 'sigmoid')\n",
        "\n",
        "autoencoder.fit(x_train, x_train,\n",
        "                epochs=num_epochs,\n",
        "                batch_size=256,\n",
        "                shuffle=True,\n",
        "                validation_data=(x_test, x_test))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "llQJkfIileTn",
        "outputId": "af22db36-b7bb-4f3f-f10c-026cf00e07c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "235/235 [==============================] - 9s 32ms/step - loss: 0.2907 - val_loss: 0.2632\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fd65693b0d0>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "activation_forward = 'linear'\n",
        "num_epochs = 1\n",
        "autoencoder = create_model('linear', 'linear')\n",
        "\n",
        "autoencoder.fit(x_train, x_train,\n",
        "                epochs=num_epochs,\n",
        "                batch_size=256,\n",
        "                shuffle=True,\n",
        "                validation_data=(x_test, x_test))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5aEy5uL2_l_e",
        "outputId": "dcda984e-a2c1-4871-d38b-a53c51a567ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "235/235 [==============================] - 6s 20ms/step - loss: 0.2043 - val_loss: 0.1346\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fd6598d6410>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class InvertedDense(layers.Dense):\n",
        "    def __init__(self, layer_sizes, *args, **kwargs):\n",
        "        self.layer_sizes = layer_sizes\n",
        "        self.kernels = []\n",
        "        self.biases = []\n",
        "        self.biases2 = []\n",
        "        self.uses_learning_phase = True\n",
        "        self.activation = kwargs['activation']\n",
        "        super().__init__(units=1, *args, **kwargs)  # 'units' not used\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        return input_shape\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        assert len(input_shape) >= 2\n",
        "        input_dim = int(input_shape[-1])\n",
        "\n",
        "        self.input_spec = layers.InputSpec(min_ndim=2, axes={-1: input_dim})\n",
        "        # print(input_dim)\n",
        "        for i in range(len(self.layer_sizes)):\n",
        "\n",
        "            self.kernels.append(\n",
        "                self.add_weight(\n",
        "                    shape=(\n",
        "                        input_dim,\n",
        "                        self.layer_sizes[i]),\n",
        "                    initializer=self.kernel_initializer,\n",
        "                    name='ae_kernel_{}'.format(i),\n",
        "                    regularizer=self.kernel_regularizer,\n",
        "                    constraint=self.kernel_constraint))\n",
        "\n",
        "            if self.use_bias:\n",
        "                self.biases.append(\n",
        "                    self.add_weight(\n",
        "                        shape=(\n",
        "                            self.layer_sizes[i],\n",
        "                        ),\n",
        "                        initializer=self.bias_initializer,\n",
        "                        name='ae_bias_{}'.format(i),\n",
        "                        regularizer=self.bias_regularizer,\n",
        "                        constraint=self.bias_constraint))\n",
        "            input_dim = self.layer_sizes[i]\n",
        "\n",
        "        if self.use_bias:\n",
        "            for n, i in enumerate(range(len(self.layer_sizes)-2, -1, -1)):\n",
        "                self.biases2.append(\n",
        "                    self.add_weight(\n",
        "                        shape=(\n",
        "                            self.layer_sizes[i],\n",
        "                        ),\n",
        "                        initializer=self.bias_initializer,\n",
        "                        name='ae_bias2_{}'.format(n),\n",
        "                        regularizer=self.bias_regularizer,\n",
        "                        constraint=self.bias_constraint))\n",
        "            self.biases2.append(self.add_weight(\n",
        "                shape=(\n",
        "                    int(input_shape[-1]),\n",
        "                ),\n",
        "                initializer=self.bias_initializer,\n",
        "                name='ae_bias2_{}'.format(len(self.layer_sizes)),\n",
        "                regularizer=self.bias_regularizer,\n",
        "                constraint=self.bias_constraint))\n",
        "\n",
        "        self.built = True\n",
        "\n",
        "    def call(self, inputs):\n",
        "        return self.decode(self.encode(inputs))\n",
        "\n",
        "    def _apply_dropout(self, inputs):\n",
        "        dropped = keras.backend.dropout(inputs, self.dropout)\n",
        "        return keras.backend.in_train_phase(dropped, inputs)\n",
        "\n",
        "    def encode(self, inputs):\n",
        "        latent = inputs\n",
        "        for i in range(len(self.layer_sizes)):\n",
        "            if self.dropout > 0:\n",
        "                latent = self._apply_dropout(latent)\n",
        "            print(self.kernels[i])\n",
        "            latent = keras.backend.dot(latent, self.kernels[i])\n",
        "            if self.use_bias:\n",
        "                print(self.biases[i])\n",
        "                latent = keras.backend.bias_add(latent, self.biases[i])\n",
        "            if self.activation is not None:\n",
        "                latent = self.activation(latent)\n",
        "        if self.l2_normalize:\n",
        "            latent = latent / keras.backend.l2_normalize(latent, axis=-1)\n",
        "        return latent\n",
        "\n",
        "    def decode(self, latent):\n",
        "        recon = latent\n",
        "        for i in range(len(self.layer_sizes)):\n",
        "            if self.dropout > 0:\n",
        "                recon = self._apply_dropout(recon)\n",
        "            print(self.kernels[len(self.layer_sizes) - i - 1])\n",
        "            recon = keras.backend.dot(recon, K.backend.transpose(\n",
        "                self.kernels[len(self.layer_sizes) - i - 1]))\n",
        "            if self.use_bias:\n",
        "                print(self.biases2[i])\n",
        "                recon = keras.backend.bias_add(recon, self.biases2[i])\n",
        "            if self.activation is not None:\n",
        "                recon = self.activation(recon)\n",
        "        return recon\n",
        "\n",
        "    def get_config(self):\n",
        "        config = {\n",
        "            'layer_sizes': self.layer_sizes\n",
        "        }\n",
        "        base_config = super().get_config()\n",
        "        base_config.pop('units', None)\n",
        "        return dict(list(base_config.items()) + list(config.items()))\n",
        "\n",
        "    @classmethod\n",
        "    def from_config(cls, config):\n",
        "        return cls(**config)"
      ],
      "metadata": {
        "id": "_t-zxVKfmpKL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# https://github.com/nanopony/keras-convautoencoder/blob/master/autoencoder_layers.py\n",
        "class DependentDense(layers.Dense):\n",
        "    def __init__(self, output_dim, master_layer, init='glorot_uniform', activation='linear', weights=None,\n",
        "                 W_regularizer=None, b_regularizer=None, activity_regularizer=None,\n",
        "                 W_constraint=None, b_constraint=None, input_dim=None, **kwargs):\n",
        "        self.master_layer = master_layer\n",
        "        super(DependentDense,self).__init__(output_dim, **kwargs)\n",
        "\n",
        "    def build(self):\n",
        "        self.W = self.master_layer.W.T\n",
        "        self.b = K.zeros((self.output_dim,))\n",
        "        self.params = [self.b]\n",
        "        self.regularizers = []\n",
        "        if self.W_regularizer:\n",
        "            self.W_regularizer.set_param(self.W)\n",
        "            self.regularizers.append(self.W_regularizer)\n",
        "\n",
        "        if self.b_regularizer:\n",
        "            self.b_regularizer.set_param(self.b)\n",
        "            self.regularizers.append(self.b_regularizer)\n",
        "\n",
        "        if self.activity_regularizer:\n",
        "            self.activity_regularizer.set_layer(self)\n",
        "            self.regularizers.append(self.activity_regularizer)\n",
        "\n",
        "        if self.initial_weights is not None:\n",
        "            self.set_weights(self.initial_weights)\n",
        "            del self.initial_weights\n",
        "\n"
      ],
      "metadata": {
        "id": "-ftl0KaLov1P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DependentBias(layers.Layer):\n",
        "    def __init__(self, master_layer, **kwargs):\n",
        "        self.master_layer = master_layer\n",
        "        super(DependentBias,self).__init__(**kwargs)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        out = inputs - self.master_layer.b\n",
        "        print('call: out', out)\n",
        "        return out\n"
      ],
      "metadata": {
        "id": "T8pVaeGCp1cj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def linear(x):\n",
        "  return x\n",
        "\n",
        "def sigmoid(x):\n",
        "    x = x + 0.000001\n",
        "    output = tf.math.sigmoid(x)\n",
        "    return output\n",
        "\n",
        "def log_sigmoid(x):\n",
        "    x = x + 0.000001\n",
        "    output = tf.math.log_sigmoid(x)\n",
        "    return output\n",
        "\n",
        "activations = { 'sigmoid': sigmoid, 'log_sigmoid': log_sigmoid, 'linear': linear}\n",
        "inverses = { 'sigmoid': 'log_sigmoid', 'linear': 'linear'}"
      ],
      "metadata": {
        "id": "DiB-ov34-MVR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# for act, func in activations:\n",
        "#     pass"
      ],
      "metadata": {
        "id": "AiJSs4TRJW7D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TiedDense(layers.Layer):\n",
        "    global activations, inverses\n",
        "    def __init__(self, master_layer):\n",
        "        super(TiedDense, self).__init__()\n",
        "        self.master_layer = master_layer\n",
        "\n",
        "    def build(self, input_shape):  # Create the state of the layer (weights)\n",
        "        \n",
        "        # self.W = self.master_layer._trainable_weights[0]\n",
        "        # self.b = self.master_layer._trainable_weights[1]\n",
        "        activation = self.master_layer.get_config()['activation']\n",
        "        self.activation = inverses[activation]\n",
        "        print('activation', self.activation)\n",
        "        # self.w = tf.transpose(self.W)\n",
        "        # self.trainable = False\n",
        "        \n",
        "    def call(self, inputs):  # Defines the computation from inputs to outputs\n",
        "        W = self.master_layer._trainable_weights[0]\n",
        "        b = self.master_layer._trainable_weights[1]\n",
        "        w = tf.transpose(W)\n",
        "        return tf.matmul((activations[self.activation](inputs) - b), w)\n",
        "    "
      ],
      "metadata": {
        "id": "C9LallIk5HHD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_palindromic_model(activation_forward):\n",
        "    input_img = keras.Input(shape=(784,))\n",
        "    a = layers.Dense(128, activation=activation_forward)\n",
        "    encoded = a(input_img)\n",
        "    b = layers.Dense(64, activation=activation_forward)\n",
        "    encoded = b(encoded)\n",
        "    c = layers.Dense(32, activation=activation_forward)\n",
        "    encoded = c(encoded)\n",
        "\n",
        "    decoded = TiedDense(c)(encoded)\n",
        "    decoded = TiedDense(b)(decoded)\n",
        "    decoded = TiedDense(a)(decoded)\n",
        "\n",
        "    autoencoder = keras.Model(input_img, decoded)\n",
        "    autoencoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
        "    autoencoder.summary()\n",
        "    autoencoder.layers[-1].trainable = False\n",
        "    autoencoder.layers[-2].trainable = False\n",
        "    autoencoder.layers[-3].trainable = False\n",
        "    return autoencoder\n"
      ],
      "metadata": {
        "id": "ZVpLJHQEpDwO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "activation_forward = 'sigmoid'\n",
        "num_epochs = 10\n",
        "autoencoder = create_palindromic_model(activation_forward)\n",
        "\n",
        "autoencoder.fit(x_train, x_train,\n",
        "                epochs=num_epochs,\n",
        "                batch_size=256,\n",
        "                shuffle=True,\n",
        "                validation_data=(x_test, x_test))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y8AHMi-ttlDJ",
        "outputId": "08e7f780-a5ae-47ca-99b5-f340b74a6252"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "activation log_sigmoid\n",
            "activation log_sigmoid\n",
            "activation log_sigmoid\n",
            "Model: \"model_7\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_11 (InputLayer)       [(None, 784)]             0         \n",
            "                                                                 \n",
            " dense_39 (Dense)            (None, 128)               100480    \n",
            "                                                                 \n",
            " dense_40 (Dense)            (None, 64)                8256      \n",
            "                                                                 \n",
            " dense_41 (Dense)            (None, 32)                2080      \n",
            "                                                                 \n",
            " tied_dense_15 (TiedDense)   (None, 64)                2080      \n",
            "                                                                 \n",
            " tied_dense_16 (TiedDense)   (None, 128)               8256      \n",
            "                                                                 \n",
            " tied_dense_17 (TiedDense)   (None, 784)               100480    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 110,816\n",
            "Trainable params: 110,816\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "235/235 [==============================] - 5s 20ms/step - loss: 1.1085 - val_loss: 1.1115\n",
            "Epoch 2/10\n",
            "235/235 [==============================] - 4s 18ms/step - loss: 0.6083 - val_loss: 0.5522\n",
            "Epoch 3/10\n",
            "235/235 [==============================] - 4s 19ms/step - loss: 0.5475 - val_loss: 0.5358\n",
            "Epoch 4/10\n",
            "235/235 [==============================] - 4s 18ms/step - loss: 0.5408 - val_loss: 0.5342\n",
            "Epoch 5/10\n",
            "235/235 [==============================] - 5s 19ms/step - loss: 0.5378 - val_loss: 0.5262\n",
            "Epoch 6/10\n",
            "235/235 [==============================] - 5s 20ms/step - loss: 0.5458 - val_loss: 0.5675\n",
            "Epoch 7/10\n",
            "235/235 [==============================] - 4s 18ms/step - loss: 0.5901 - val_loss: 0.5843\n",
            "Epoch 8/10\n",
            "235/235 [==============================] - 5s 19ms/step - loss: 0.6238 - val_loss: 0.6242\n",
            "Epoch 9/10\n",
            "235/235 [==============================] - 4s 19ms/step - loss: 0.6288 - val_loss: 0.6245\n",
            "Epoch 10/10\n",
            "235/235 [==============================] - 5s 20ms/step - loss: 0.6319 - val_loss: 0.5647\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fd6554795d0>"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(autoencoder.layers[-1]._trainable_weights)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tnogr4ppuxl2",
        "outputId": "8df54a70-e235-4073-8b56-07ab66bdfecf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "UXO0OBW3CNYF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}